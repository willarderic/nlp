
# this is ../me/mimi/chores/teaching/current/nlp/class_notes/homework/hw1.org


#+title: Homework 1:  Getting Started and the Structural Units of Language
#+author: Toni Kazic
#+date: Fall, 2023

# revised text of qs 31--34 <2021-08-25 Wed>
#
# revised text of qs 38 (bo-tagger) and 39 <2021-09-14 Tue>


#+SETUPFILE: "../../../common/preamble.org"
#+LATEX_CLASS: article
#+OPTIONS: toc:nil
#+OPTIONS: ^:nil

#+LATEX_HEADER: \usepackage{langsci-avm}
# http://ftp.math.purdue.edu/mirrors/ctan.org/macros/latex/contrib/langsci-avm/langsci-avm.pdf

#+LATEX_HEADER: \newcommand{\grmr}[2]{\ensuremath{\mathrm{#1} & \,\longrightarrow\, \mathrm{#2}}}
#+LATEX_HEADER: \newcommand{\txtgrmr}[2]{\ensuremath{\mathrm{#1} \,\longrightarrow\, \mathrm{#2}}}
#+LATEX_HEADER: \newcommand{\grmrhs}[1]{\ensuremath{& \,\longrightarrow\, \mathrm{#1} }}
#+LATEX_HEADER: \newcommand{\wa}[1]{\type{\textnormal{\w{#1}}}}

# compile with pdflatex
#
# Kazic, 3.11.2020


# fixed question numbering on latex export, at the cost of removing line
# feeds and a little hard-wiring.
#
# It's possible to set the org-empty-line-terminates-plain-lists
#
# Kazic, 31.8.2021
#
# finally, cross-linking on list items!
# https://stackoverflow.com/questions/28151373/orgmode-referring-to-an-item-in-a-numbered-list
#
# Kazic, 1.9.2021


* Introduction

This homework lays the foundation for the course to help you work smoothly
through the semester.  It starts our work on several course objectives and
introduces the basic structural units of languages.  We'll explore some
linguistic and computational approaches to these units.



* Who's Who and Solution Patterns
<<whoswho>>



** Group Members

| first name last name | color                         |
|----------------------+-------------------------------|
| Eric                 | green \color{green}\rule{5mm}{3mm} |
|                      | yellow \color{yellow}\rule{5mm}{3mm} |
|                      | purple \color{violet}\rule{5mm}{3mm} |




** Two Member Solution Patterns

| color                         | draft solution | revise solution |
|-------------------------------+----------------+-----------------|
| green \color{green}\rule{5mm}{3mm} | odds           | evens           |
| yellow \color{yellow}\rule{5mm}{3mm} | evens          | odds            |


** Three Member Solution Patterns

$i$ is the question number.

#+begin_center
#+ATTR_LaTeX: :mode inline-math :environment array
| \text{color}                  | \text{draft solution} | \text{revise solution} |
|-------------------------------+----------------+-----------------|
| green \color{green}\rule{5mm}{3mm} | i \mod 3 = 1   | i \mod 3 = 0    |
| yellow \color{yellow}\rule{5mm}{3mm} | i \mod 3 = 2   | i \mod 3 = 1    |
| purple \color{violet}\rule{5mm}{3mm} | i \mod 3 = 0   | i \mod 3 = 2    |
#+end_center


* General Instructions

   + /Fill out the group members table and follow the solution patterns/ in
     Section [[whoswho]].

   + /If the question is unclear, tell me your interpretation of it as part
     of your answer./  Feel free to ask about the questions in class or on
     the Slack channel (use =@channel= as others will probably be puzzled
     too). 

   + /For questions using corpora, use the corpus of the lead person./

   + /Put your draft answers right after each question using a *complete,
     functional* =org= mode code or example block./ Make sure your code
     block is complete and functional by testing it in your copy of this
     homework file.

   + /Each group member reviews the others' draft solutions and you revise them together/.

   + /Discuss each other's draft and reviews, finalizing the answers./

   + /Show all your work: code, results, and analysis./  Does your code
     work in this file and produce *exactly* the results you show? 

   + /Post the completed file to Canvas no later than noon on the Tuesday
     indicated/ in the [[../syllabus.org::schedule][schedule in the syllabus]], naming your file with each
     person's first name (no spaces in the file name, and don't forget the
     =.org= extension!).  Only one person should submit the final file.


   
* Hints

** Follow the instructions in [[file:../notes.org::tech][the technical setup section of the notes]].
Briefly: install [[https://www.gnu.org/software/emacs/download.html][emacs]] for your operating systems; take its tutorial;
install [[file:../../../common/mechanics/pythonesque.org][python and nltk (including the data)]]; practice the examples in
[[file:../mechanics/python_org_mode.org][python_org_mode.org]]; and explore the [[http://www.nltk.org/nltk_data/][various corpora available]].


** *Don't use :session in your code block header!* 
It makes the code blocks interdependent, and I don't want to make a mistake
when cutting and pasting your code to test it.  I should be able to
reproduce your results exactly by running your code block in =org=, so
if it doesn't run you're headed for toast.


** Don't overthink this!

The point of using =NLTK= is to learn it, not re-invent it unless there is a
very good reason.  If you mistrust an answer it gives you, then coding from
scratch and /comparing the results as part of your answer/ is good.


This also applies to =scikit-learn=!




** Make sure you get the right version of the book and documentation when googling.

There are many examples drawn from the first edition of the book and NLTK
2.0 out on the web.  Syntax and functionality have changed between NLTK 2.0
and 3.0:  here's [[https://streamhacker.com/2014/12/02/nltk-3/][a short rundown on these]].



** Some Variations on Loading Python Modules

+ If you just say "import nltk", python doesn't enter the names of any of
  the functions contained within the nltk module into the current symbol
  table.  So when you want to call a function, you have to use the dot
  notation:
#+BEGIN_EXAMPLE
nltk.FCN_NAME()
#+END_EXAMPLE






+ You can import specific functions into the current symbol table:
#+BEGIN_EXAMPLE
from nltk import FCN
#+END_EXAMPLE


And when you do this, they can be called directly:
#+BEGIN_EXAMPLE
FCN()
#+END_EXAMPLE




+ Or, you can import all of the functions at once:
#+BEGIN_EXAMPLE
from nltk import *
#+END_EXAMPLE


and then call them directly:
#+BEGIN_EXAMPLE
FCN()
#+END_EXAMPLE


Importing all the functions in a package or module is generally frowned
upon by the Pythonistas as one wouldn't necessarily know all the names of the 
functions in a module, and they don't want python to confuse the symbols.  While
you can see the current symbol table by typing 
#+BEGIN_EXAMPLE
dir()
#
# or, that for a particular package,
#
dir(nltk)
#+END_EXAMPLE
you might want to play it safe.



+ Finally, you might want to abbreviate a function's (or submodule's) name when you import it:
#+BEGIN_EXAMPLE
import matplotlib.pyplot as plt
. . .
plt.savefig()
#+END_EXAMPLE



** What Can I Do with This Data Structure?

Python implements many data structures, like integers (int), lists ([]),
tuples (()), sets ({}), and dictionaries (aka associative arrays or
key-value lists).  To quickly see what built-in functions are available
for a data structure and get a little help on them:

#+begin_src python
#
# define an empty list
#
L = []
dir(L)

t = ()
dir(t)

help(t.count)

# type q to get back to the python prompt

#+end_src








** If you don't see any output with #+begin_src python :results output, try a print()




** defaultdict is an essentially empty data structure!

For example, it's *not* a dictionary of words and tags.



** Get the right input for the frequency distributions.

In a conditional frequency distribution built from a tagged corpus, the
keys are the tokens and the values are the tags.  NLTK calls the keys
/conditions/: for example, the condition for the value = 'AT' is that the
key = 'the'.  That's very different from the unconditioned frequency
distribution.




** Useful Web Sites

You may find the [[https://docs.python.org/3/tutorial/index.html][official python tutorial]] useful, especially the earlier sections (I did).

[[https://docs.python.org/3/faq/index.html][A collection of Python FAQs]].

[[http://www.nltk.org/py-modindex.html][Index to the current versions of NLTK modules and functions.]]  The examples
in the book may not always be current with the state of the code.


[[https://en.wikipedia.org/wiki/English_prefix][Wikipedia has a fairly thorough list]] of prefixes, but let's use the list of the most
common prefixes found at [[http://dictionary.cambridge.org/us/grammar/british-grammar/prefixes][the Cambridge English Grammar]] site:

#+begin_src python :results output
prefixes = ['anti','auto','de','dis','down','extra','hyper','il','im','in','ir','inter',
             'mega','mid','mis','non','over','out','post','pre','pro','re','semi','sub',
             'super','tele','trans','ultra','un','under','up']
#+end_src







* Questions 

# revised <2021-10-14 Thu> to eliminate freebie



** What are Your GitHub Handles and Corpus Preferences?  Fill Out Here and DM me the answers.

1. [@1] If you don't already have one, get a [[https://github.com/][GitHub handle]] and DM this table to
   me on Slack.

| first name | color                                | GitHub handle |
|------------+--------------------------------------+---------------|
| Eric       | green \color{green}\rule{5mm}{3mm}   | willarderic   |
|            | yellow \color{yellow}\rule{5mm}{3mm} |               |
|            | purple \color{violet}\rule{5mm}{3mm} |               |

For each person in your team, please list in order of decreasing preference
your top three choices for corpora.  Be careful to choose a corpus, not a
model, lexicon, or other lexical aid.  Suggestion: load interesting corpora
and get a few sentences from each.

Please DM me the filled out table on Slack by our third class so I can
resolve any conflicts!

| first name | first choice | second choice | third choice |
|------------+--------------+---------------+--------------|
| Eric       | brown        | gutenberg     | abc          |
|            |              |               |              |
|            |              |               |              |







** 21 emacs questions

# see
# https://stackoverflow.com/questions/28351465/emacs-orgmode-do-not-insert-line-between-headers

Answer the emacs questions giving the KEYSTROKES, following the emacs
conventions for the control and meta keys.  Some questions require answers
in English: stick those in an example block too.


2. [@2] How do you start emacs from the command line?

3. How do you open a file?

4. How do you edit it?
Put the cursor where you want to make a change and insert and/or delete
characters from there.
5. How do you save it?

6. How do you get help without googling?

7. How do you get out of trouble?
C+g is a command to cancel your current command, which would get you out of trouble.
# second clause added <2021-10-12 Tue>
#
8.  How do you split the window in half horizontally, so that one half is above the other?

# second clause added <2021-10-12 Tue>
#
9.  How do you split the window in half vertically, so that the halves are side by side?

10.  How long can you repeat the operations in questions 8 and 9?
You can repeat the operations from 8 or 9 four times from the starting
section, but I was able to get 8 total vertical "halves" by splitting the
other "halves". You can continue until a pane is too small to be split anymore.
11.  What is a buffer?

12.  How do you get a list of all the buffers running in your emacs
     process?
13.  How do you jump to the top of the file without scrolling?
The command M+< allows you to jump to the top of the file without scrolling.
14.  How do you jump to the bottom of the file without scrolling?

15.  How do you move down a page without scrolling?

16.  How do you move up a page without scrolling?
To move up a page without scrolling, use the command M+v
17.  How do you move to the end of a line?

18.  How do you move to the beginning of a line?

19.  What is the point?
The point is the current location of the cursor.
20.  What is the mark?

# revised to specify mark and point, <2022-10-12 Wed>    
21.  Why are the mark and point useful?

22.  How do you exit emacs?
The sequence of commands to exit is C+x C+c

Answer the remaining questions with a corpus of your choice  from the NLTK book.


** 6 python/nltk questions


23.  [@23] What is the command to insert a python code block template?

24.  Load nltk and import the corpus using a python code block.

25.  How many unique tokens are in your corpus?
#+begin_src python :results output
from nltk.corpus import brown
print(len(set(brown.words())))
#+end_src

#+results:
: 56057
There are 56057 unique tokens in the entire corpus.


26.  Print out the first 1000 tokens in your corpus.

27.  Why do the tokens include punctuation?

28.  How many unique tokens are in the first 1000?
#+begin_src python :results output
from nltk.corpus import brown
print(len(set(brown.words()[:1000])))
#+end_src

#+results:
: 438
There are 438 unique tokens in the first 1000 tokens.





** 6 morpheme/morphosyntax/N-gram questions


29.  [@29] How many of each of the principal modal verbs occur in your corpus?

30.  How many unique bigrams are in your text?

# stopword caution
31.  How many bigrams contain the modal \w{can}?  Compute both for all and the
    unique bigrams.  Don't exclude stopwords!
#+begin_src python :results output
from nltk.corpus import brown
from nltk.util import bigrams
bigrams = list(bigrams(brown.words()))
count = 0
for bigram in bigrams:
  if bigram[0] == 'can' or bigram[1] == 'can':
    count = count + 1
print(count)
#+end_src

#+results:
: 3476
I counted 3476 bigrams containing the modal \w{can}.

# revised to insist on a prefix
# <<pref-regex>>
32.  <<pref-regex>> Choose a prefix from the list above and write a regular expression
    that identifies *all* words in your corpus containing that prefix
    (remember that a prefix begins the word).  What's the length of that
    group of words?
#+begin_src python :results output
from nltk.corpus import brown
import re

# I chose the prefix 'mega'
prefix_words = [s for s in brown.words() if re.search(r'^mega[a-zA-Z\-]', s)]
print(len(prefix_words))
print(len(set(prefix_words)))
#+end_src

#+results:
: 17
: 6
There are 17 words in the brown corpus that have the prefix
"mega". Counting only unique words, there are 6 in total.

# revised to specify what to show
# pref-regex
33.  <<sort-set>> Sort the set of problem [[pref-regex]] in alphabetical order (show your code and
    results) and study it.  Do you see multiple forms of the same headword?
    Show some examples.
#+begin_src python :results output
from nltk.corpus import brown
import re

# I chose the prefix "mega"
prefix_words = [s for s in brown.words() if re.search(r'^mega[a-zA-Z\-]', s)]

print(sorted(set(prefix_words)))
#+end_src

#+results:
: ['megakaryocytic', 'megalomania', 'megalopolises', 'megaton', 'megatons', 'megawatt']
The only repeated headwords I see are 'megaton' and the plural of it, 'megatons'.

# revised to specify what to show, changed back-pointer
# fixed back-pointer again
# pref-regex
34.  Now use the Porter stemmer on the set from problem [[sort-set]] (again, show
    your code and results).  What do you notice?
#+begin_src python :results output
from nltk.stem.porter import *
mega_prefixes = ['megakaryocytic', 'megalomania', 'megalopolises', 'megaton', 'megatons', 'megawatt']
stemmer = PorterStemmer()
stemmed_words = [stemmer.stem(w) for w in mega_prefixes]
print(stemmed_words)
print(len(set(stemmed_words)))
#+end_src

#+results:
: ['megakaryocyt', 'megalomania', 'megalopolis', 'megaton', 'megaton', 'megawatt']
: 5
The PorterStemmer removed the plurality of the word 'megatons' to produce
'megaton'. After this stemming, there are only 5 unique headwords that
start with the prefix 'mega'. 


** 8 Tags, Tagsets, and Tagging
SCHEDULED: <2023-09-26 Tue>

35.  [@35] Ask NLTK what tags the Penn Treebank tagset uses for nouns and verbs
    (and show the result).

#  <<ran-sent>> 



#+results:
: 19701

36. <<ran-sent>> Import the corpus and count the number of sentences in it, discarding
    any uninteresting front matter such as titles and chapter headings.
    Then show a random sentence.
#+begin_src python :results output
from nltk.corpus import brown
import random
sents = brown.sents()
num_sents = len(brown.sents())
#random_sentence_index = random.randint(0, num_sents)
# The random number I received from the above call was 19701, I will save the index for future problems.
random_sentence_index = 19701
print(sents[random_sentence_index])
#+end_src

#+results:
: ['By', 'counting', 'the', 'number', 'of', 'stalls', 'and', 'urinals', 'I', 'attempted', 'to', 'form', 'a', 'loose', 'estimate', 'of', 'how', 'many', 'men', 'the', 'hall', 'would', 'hold', 'at', 'one', 'time', '.']


37.  Tag each token in your random sentence as 'VB'.

#+begin_src python :results output

from nltk.corpus import brown
from nltk.tag import DefaultTagger
random_sentence_index = 19701
sents = brown.sents()
default_tagger = DefaultTagger('VB')
tagged_sentence = default_tagger.tag(sents[random_sentence_index])
print(tagged_sentence)
#+end_src

#+results:
: [('With', 'VB'), ('few', 'VB'), ('exceptions', 'VB'), (',', 'VB'), ('the', 'VB'), ('major', 'VB'), ('denominations', 'VB'), ('are', 'VB'), ('rapidly', 'VB'), ('losing', 'VB'), ('their', 'VB'), ('hold', 'VB'), ('on', 'VB'), ('the', 'VB'), ('central', 'VB'), ('city', 'VB'), ('.', 'VB')]

    # <<silly-tags>>
38. <<silly-tags>> Of course that's pretty silly, but we can make it even sillier.  Build
	a dictionary of the incorrectly tagged words in your sentence using the
	following tags:
#+begin_src python
silly = ['FOO','BAR','EGO','NEED','ADS','DUCK','MANSE'
#+end_src
#  [[ran-sent]]


39. [@39]  <<bo-tagger>> Construct a lookup tagger trained on the 1000 most frequent words in
    the Brown news category that backs off to a default tag of 'UNK'.  Use
    that to tag the original random sentence you got in question [[ran-sent]].  Print
    the result as the list of tuples in sentence order.  What do you
    observe?
#+begin_src python :results output
import nltk
from nltk.corpus import brown
freq_dist = nltk.FreqDist(brown.words(categories='news'))
cond_freq_dist = nltk.ConditionalFreqDist(brown.tagged_words(categories='news'))
most_freq_words = freq_dist.most_common(1000)
freq_tags = dict((word, cond_freq_dist[word].max()) for (word, _) in most_freq_words)
botagger = nltk.UnigramTagger(model=freq_tags, backoff=nltk.DefaultTagger('UNK'))
sents = brown.sents()
print(botagger.tag(sents[19701]))
#+end_src

#+results:
: [('With', 'IN'), ('few', 'AP'), ('exceptions', 'UNK'), (',', ','), ('the', 'AT'), ('major', 'JJ'), ('denominations', 'UNK'), ('are', 'BER'), ('rapidly', 'UNK'), ('losing', 'UNK'), ('their', 'PP$'), ('hold', 'UNK'), ('on', 'IN'), ('the', 'AT'), ('central', 'JJ'), ('city', 'NN'), ('.', '.')]
The bo-tagger seems to be able to tag at least half of the sentence. The more common words are definitely the ones getting tagged, whereas
more uncommon words such as 'denominations' are being tagged 'UNK'.


#  ran-sent and bo-tagger
40. [@40] For your random sentence found in question [[ran-sent]] tagged with
    the tagger you built in question [[bo-tagger]], write a
    transformational rule the Brill tagger might discover for the each of
    the first three UNK tags.  Put these in an example block as ordinary
    text, /e.g./:
#+BEGIN_EXAMPLE
tagged sentence
rule 1: If the preceding word is 'few':  UNK -> NN
rule 2: If the preceding word is 'JJ' (an adjective): UNK -> NN
rule 3: If the word i-1 is 'are' and word i+1 is 'VB', 'RB', or 'UNK': UNK -> RB
#+END_EXAMPLE



This problem relies on a problem my team members were responsible for, and
they did not complete nor ask for help until right before the homework deadline.
# <<to-gram>>
41. [@41]  <<to-gram>> Example 2.2 in [[http://www.nltk.org/book/ch07.html][chapter 7]] shows a little grammar for noun phrase
    chunking.  Let's mix it up a bit and define a grammar for "to phrases":
    bigrams that begin with the tag =TO=.  Show the total parse and just
    the "to phrases" (just edit away the rest unless you feel like getting
    fancy). Use the following sentence to build and test your grammar:
#+begin_src python

# more convenient one-liner
tj = [('He', 'PPS'), ('had', 'HVD'), ('nothing', 'UNK'), ('to', 'TO'), ('urge', 'UNK'), ('against', 'IN'), ('it', 'PPS'), (',', ','), ('but', 'CC'), ('still', 'RB'), ('resisted', 'UNK'), ('the', 'AT'), ('idea', 'UNK'), ('of', 'IN'), ('a', 'AT'), ('letter', 'UNK'), ('of', 'IN'), ('proper', 'UNK'), ('submission', 'UNK'), (';', '.'), ('and', 'CC'), ('therefore', 'UNK'), (',', ','), ('to', 'TO'), ('make', 'VB'), ('it', 'PPS'), ('easier', 'UNK'), ('to', 'TO'), ('him', 'PPO'), (',', ','), ('as', 'CS'), ('he', 'PPS'), ('declared', 'VBD'), ('a', 'AT'), ('much', 'AP'), ('greater', 'UNK'), ('willingness', 'UNK'), ('to', 'TO'), ('make', 'VB'), ('mean', 'UNK'), ('concessions', 'UNK'), ('by', 'IN'), ('word', 'NN'), ('of', 'IN'), ('mouth', 'UNK'), ('than', 'IN'), ('on', 'IN'), ('paper', 'UNK'), (',', ','), ('it', 'PPS'), ('was', 'BEDZ'), ('resolved', 'UNK'), ('that', 'CS'), (',', ','), ('instead', 'UNK'), ('of', 'IN'), ('writing', 'UNK'), ('to', 'TO'), ('Fanny', 'UNK'), (',', ','), ('he', 'PPS'), ('should', 'MD'), ('go', 'VB'), ('to', 'TO'), ('London', 'UNK'), (',', ','), ('and', 'CC'), ('personally', 'UNK'), ('intreat', 'UNK'), ('her', 'PP$'), ('good', 'JJ'), ('offices', 'UNK'), ('in', 'IN'), ('his', 'PP$'), ('favour', 'UNK'), ('.--', 'UNK'), ('"', 'UNK'), ('And', 'CC'), ('if', 'CS'), ('they', 'PPSS'), ('really', 'RB'), ('DO', 'UNK'), ('interest', 'NN'), ('themselves', 'PPLS'), (',"', 'UNK'), ('said', 'VBD'), ('Marianne', 'UNK'), (',', ','), ('in', 'IN'), ('her', 'PP$'), ('new', 'JJ'), ('character', 'UNK'), ('of', 'IN'), ('candour', 'UNK'), (',', ','), ('"', 'UNK'), ('in', 'IN'), ('bringing', 'UNK'), ('about', 'IN'), ('a', 'AT'), ('reconciliation', 'UNK'), (',', ','), ('I', 'PPSS'), ('shall', 'UNK'), ('think', 'VB'), ('that', 'CS'), ('even', 'RB'), ('John', 'NP'), ('and', 'CC'), ('Fanny', 'UNK'), ('are', 'BER'), ('not', '*'), ('entirely', 'UNK'), ('without', 'IN'), ('merit', 'UNK'), ('."', 'UNK')]

# for prettier printing

tj = [('He', 'PPS'), ('had', 'HVD'), ('nothing', 'UNK'), ('to', 'TO'), ('urge', 'UNK'), 
      ('against', 'IN'), ('it', 'PPS'), (',', ','), ('but', 'CC'), ('still', 'RB'), 
      ('resisted', 'UNK'), ('the', 'AT'), ('idea', 'UNK'), ('of', 'IN'), ('a', 'AT'), 
      ('letter', 'UNK'), ('of', 'IN'), ('proper', 'UNK'), ('submission', 'UNK'), (';', '.'), 
      ('and', 'CC'), ('therefore', 'UNK'), (',', ','), ('to', 'TO'), ('make', 'VB'), 
      ('it', 'PPS'), ('easier', 'UNK'), ('to', 'TO'), ('him', 'PPO'), (',', ','), 
      ('as', 'CS'), ('he', 'PPS'), ('declared', 'VBD'), ('a', 'AT'), ('much', 'AP'), 
      ('greater', 'UNK'), ('willingness', 'UNK'), ('to', 'TO'), ('make', 'VB'), 
      ('mean', 'UNK'), ('concessions', 'UNK'), ('by', 'IN'), ('word', 'NN'), ('of', 'IN'), 
      ('mouth', 'UNK'), ('than', 'IN'), ('on', 'IN'), ('paper', 'UNK'), (',', ','), ('it', 'PPS'), 
      ('was', 'BEDZ'), ('resolved', 'UNK'), ('that', 'CS'), (',', ','), 
      ('instead', 'UNK'), ('of', 'IN'), ('writing', 'UNK'), ('to', 'TO'), 
      ('Fanny', 'UNK'), (',', ','), ('he', 'PPS'), ('should', 'MD'), ('go', 'VB'), 
      ('to', 'TO'), ('London', 'UNK'), (',', ','), ('and', 'CC'), ('personally', 'UNK'), 
      ('intreat', 'UNK'), ('her', 'PP$'), ('good', 'JJ'), ('offices', 'UNK'), ('in', 'IN'), 
      ('his', 'PP$'), ('favour', 'UNK'), ('.--', 'UNK'), ('"', 'UNK'), ('And', 'CC'), 
      ('if', 'CS'), ('they', 'PPSS'), ('really', 'RB'), ('DO', 'UNK'), ('interest', 'NN'), 
      ('themselves', 'PPLS'), (',"', 'UNK'), ('said', 'VBD'), ('Marianne', 'UNK'), 
      (',', ','), ('in', 'IN'), ('her', 'PP$'), ('new', 'JJ'), ('character', 'UNK'), 
      ('of', 'IN'), ('candour', 'UNK'), (',', ','), ('"', 'UNK'), ('in', 'IN'), 
      ('bringing', 'UNK'), ('about', 'IN'), ('a', 'AT'), ('reconciliation', 'UNK'), 
      (',', ','), ('I', 'PPSS'), ('shall', 'UNK'), ('think', 'VB'), ('that', 'CS'), 
      ('even', 'RB'), ('John', 'NP'), ('and', 'CC'), ('Fanny', 'UNK'), ('are', 'BER'), 
      ('not', '*'), ('entirely', 'UNK'), ('without', 'IN'), ('merit', 'UNK'), ('."', 'UNK')]
#+end_src

#  [[to-gram]], 40
42.  [@42] What do you observe in your results for question [[to-gram]]?  Why do you think
    this is happening?




* Grading Scale

# revised <2021-10-14 Thu> to correct typo

This homework is worth 15 points.  Complete answers for question 1, here
and in the Slack channel, are required: otherwise /no/ points will be
awarded.  The grading scale is:

| fraction correctly reviewed and answered | points awarded |
|------------------------------------------+----------------|
| \(\ge 0.95\)                             |             15 |
| 0.90 -- 0.94                             |             14 |
| 0.85 -- 0.89                             |             13 |
| 0.80 -- 0.84                             |             12 |
| 0.75 -- 0.79                             |             11 |
| 0.70 -- 0.74                             |             10 |
| 0.65 -- 0.69                             |              9 |
| 0.60 -- 0.64                             |              8 |
| 0.55 -- 0.59                             |              7 |
| 0.50 -- 0.54                             |              6 |
| 0.45 -- 0.49                             |              5 |
| 0.40 -- 0.44                             |              4 |
| 0.35 -- 0.39                             |              3 |
| 0.30 -- 0.34                             |              2 |
| 0.25 -- 0.29                             |              1 |
| \(< 0.25\)                               |              0 |




* Scoring




|     question | ok? |
|--------------+-----|
|            1 |     |
|            2 |     |
|            3 |     |
|            4 |     |
|            5 |     |
|            6 |     |
|            7 |     |
|            8 |     |
|            9 |     |
|           10 |     |
|           11 |     |
|           12 |     |
|           13 |     |
|           14 |     |
|           15 |     |
|           16 |     |
|           17 |     |
|           18 |     |
|           19 |     |
|           20 |     |
|           21 |     |
|           22 |     |
|           23 |     |
|           24 |     |
|           25 |     |
|           26 |     |
|           27 |     |
|           28 |     |
|           29 |     |
|           30 |     |
|           31 |     |
|           32 |     |
|           33 |     |
|           34 |     |
|           35 |     |
|           36 |     |
|           37 |     |
|           38 |     |
|           39 |     |
|           40 |     |
|           41 |     |
|           42 |   0 |
|--------------+-----|
|  total score |   0 |
|     fraction |   0 |
| total points |     |
#+TBLFM: @44$2=vsum(@I..@II)::@45$2=@-1/(@-2$1)

